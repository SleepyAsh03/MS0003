{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6feaa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to standardize and parse the datetime string correctly\n",
    "def standardize_parse_datetime(date_str, time_str):\n",
    "    parts = date_str.split('/')\n",
    "    if len(parts[2]) == 2:\n",
    "        parts[2] = '20' + parts[2]  # Assuming all dates are in the 2000s\n",
    "    standardized_date_str = '/'.join(parts)\n",
    "    datetime_str = standardized_date_str + ' ' + time_str\n",
    "    return pd.to_datetime(datetime_str, format='%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "# Load the data\n",
    "plant1_data = pd.read_csv('Plant_1_Generation_Data.csv')\n",
    "plant2_data = pd.read_csv('Plant_2_Generation_Data.csv')\n",
    "solar_data = pd.read_csv('SolarRecording.csv')\n",
    "\n",
    "# Convert DATE_TIME in plant data to datetime for consistency\n",
    "plant1_data['DATE_TIME'] = pd.to_datetime(plant1_data['DATE_TIME'], format='%d/%m/%y %H:%M')\n",
    "plant2_data['DATE_TIME'] = pd.to_datetime(plant2_data['DATE_TIME'], format='%d/%m/%y %H:%M')\n",
    "\n",
    "# Combine plant data\n",
    "combined_plant_data = pd.concat([plant1_data, plant2_data])\n",
    "\n",
    "# Standardize and parse the datetime in solar data\n",
    "solar_data['DateTime'] = solar_data.apply(lambda row: standardize_parse_datetime(row['Date'], row['Time']), axis=1)\n",
    "\n",
    "# Merge the combined plant data with solar data on the nearest datetime\n",
    "merged_data = pd.merge_asof(combined_plant_data.sort_values('DATE_TIME'), \n",
    "                            solar_data.sort_values('DateTime'), \n",
    "                            left_on='DATE_TIME', \n",
    "                            right_on='DateTime', \n",
    "                            direction='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ef2ba55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timmyboi/anaconda3/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0722\n",
      "Epoch 2/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0598\n",
      "Epoch 3/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0567\n",
      "Epoch 4/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0559\n",
      "Epoch 5/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0547\n",
      "Epoch 6/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0534\n",
      "Epoch 7/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0526\n",
      "Epoch 8/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0512\n",
      "Epoch 9/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0508\n",
      "Epoch 10/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0496\n",
      "Epoch 11/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0492\n",
      "Epoch 12/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0488\n",
      "Epoch 13/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0475\n",
      "Epoch 14/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0476\n",
      "Epoch 15/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0464\n",
      "Epoch 16/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0467\n",
      "Epoch 17/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0455\n",
      "Epoch 18/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0458\n",
      "Epoch 19/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0451\n",
      "Epoch 20/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0440\n",
      "Epoch 21/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0436\n",
      "Epoch 22/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0441\n",
      "Epoch 23/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0433\n",
      "Epoch 24/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0433\n",
      "Epoch 25/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0429\n",
      "Epoch 26/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0427\n",
      "Epoch 27/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0427\n",
      "Epoch 28/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0420\n",
      "Epoch 29/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0414\n",
      "Epoch 30/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0418\n",
      "Epoch 31/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0413\n",
      "Epoch 32/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0414\n",
      "Epoch 33/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0413\n",
      "Epoch 34/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0409\n",
      "Epoch 35/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0406\n",
      "Epoch 36/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0404\n",
      "Epoch 37/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0401\n",
      "Epoch 38/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0400\n",
      "Epoch 39/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0394\n",
      "Epoch 40/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0388\n",
      "Epoch 41/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0395\n",
      "Epoch 42/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0389\n",
      "Epoch 43/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0385\n",
      "Epoch 44/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0389\n",
      "Epoch 45/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0386\n",
      "Epoch 46/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0384\n",
      "Epoch 47/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0379\n",
      "Epoch 48/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0379\n",
      "Epoch 49/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0375\n",
      "Epoch 50/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0375\n",
      "Epoch 51/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0377\n",
      "Epoch 52/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0374\n",
      "Epoch 53/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0374\n",
      "Epoch 54/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0372\n",
      "Epoch 55/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0371\n",
      "Epoch 56/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0369\n",
      "Epoch 57/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0366\n",
      "Epoch 58/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0365\n",
      "Epoch 59/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0365\n",
      "Epoch 60/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0364\n",
      "Epoch 61/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0362\n",
      "Epoch 62/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0362\n",
      "Epoch 63/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0359\n",
      "Epoch 64/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0362\n",
      "Epoch 65/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0357\n",
      "Epoch 66/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0362\n",
      "Epoch 67/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0359\n",
      "Epoch 68/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0354\n",
      "Epoch 69/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0353\n",
      "Epoch 70/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0349\n",
      "Epoch 71/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0352\n",
      "Epoch 72/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0351\n",
      "Epoch 73/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0350\n",
      "Epoch 74/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0358\n",
      "Epoch 75/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0353\n",
      "Epoch 76/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0357\n",
      "Epoch 77/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0346\n",
      "Epoch 78/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0349\n",
      "Epoch 79/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0350\n",
      "Epoch 80/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0346\n",
      "Epoch 81/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0348\n",
      "Epoch 82/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0347\n",
      "Epoch 83/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0346\n",
      "Epoch 84/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0350\n",
      "Epoch 85/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0340\n",
      "Epoch 86/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0344\n",
      "Epoch 87/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0341\n",
      "Epoch 88/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0345\n",
      "Epoch 89/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0342\n",
      "Epoch 90/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0342\n",
      "Epoch 91/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0343\n",
      "Epoch 92/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0341\n",
      "Epoch 93/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0338\n",
      "Epoch 94/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0333\n",
      "Epoch 95/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0339\n",
      "Epoch 96/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0341\n",
      "Epoch 97/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0344\n",
      "Epoch 98/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0338\n",
      "Epoch 99/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0339\n",
      "Epoch 100/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0335\n",
      "Epoch 101/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0333\n",
      "Epoch 102/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0337\n",
      "Epoch 103/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0335\n",
      "Epoch 104/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0335\n",
      "Epoch 105/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0337\n",
      "Epoch 106/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0338\n",
      "Epoch 107/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0336\n",
      "Epoch 108/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0335\n",
      "Epoch 109/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0336\n",
      "Epoch 110/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0336\n",
      "Epoch 111/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0341\n",
      "Epoch 112/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0336\n",
      "Epoch 113/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0331\n",
      "Epoch 114/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0331\n",
      "Epoch 115/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0332\n",
      "Epoch 116/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0329\n",
      "Epoch 117/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0332\n",
      "Epoch 118/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0331\n",
      "Epoch 119/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0330\n",
      "Epoch 120/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0329\n",
      "Epoch 121/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0329\n",
      "Epoch 122/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0322\n",
      "Epoch 123/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0336\n",
      "Epoch 124/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0329\n",
      "Epoch 125/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0330\n",
      "Epoch 126/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0326\n",
      "Epoch 127/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0331\n",
      "Epoch 128/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0332\n",
      "Epoch 129/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0329\n",
      "Epoch 130/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0324\n",
      "Epoch 131/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0330\n",
      "Epoch 132/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0334\n",
      "Epoch 133/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0327\n",
      "Epoch 134/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0325\n",
      "Epoch 135/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0328\n",
      "Epoch 136/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0324\n",
      "Epoch 137/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0326\n",
      "Epoch 138/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0324\n",
      "Epoch 139/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0328\n",
      "Epoch 140/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0327\n",
      "Epoch 141/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0324\n",
      "Epoch 142/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0323\n",
      "Epoch 143/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0325\n",
      "Epoch 144/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0326\n",
      "Epoch 145/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0321\n",
      "Epoch 146/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0327\n",
      "Epoch 147/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0331\n",
      "Epoch 148/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0327\n",
      "Epoch 149/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0324\n",
      "Epoch 150/150\n",
      "\u001b[1m1092/1092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2898bac10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming merged_data is preprocessed and ready for modeling\n",
    "\n",
    "# Feature selection\n",
    "features = merged_data[['Radiation', 'Temperature', 'Pressure', 'Humidity', 'WindDirection(Degrees)', 'Speed']]\n",
    "target = merged_data['DAILY_YIELD']\n",
    "\n",
    "# Normalize the features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "scaled_target = scaler.fit_transform(target.values.reshape(-1, 1))\n",
    "\n",
    "# Function to create sequences for LSTM\n",
    "def create_sequences(features, target, time_steps=1):\n",
    "    X, y = [], []\n",
    "    for i in range(len(features) - time_steps):\n",
    "        v = features[i:(i + time_steps)]\n",
    "        X.append(v)\n",
    "        y.append(target[i + time_steps])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Creating time series sequences\n",
    "time_steps = 10  # Number of time steps you want to look back\n",
    "X, y = create_sequences(scaled_features, scaled_target, time_steps)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the LSTM model with a ReLU activation function in the output layer\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(time_steps, X_train.shape[2])))\n",
    "model.add(Dense(1, activation='relu'))  # ReLU to ensure non-negative predictions\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1098fffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Predicted Daily Yield for one day after the dataset ends: 5680.96240234375\n"
     ]
    }
   ],
   "source": [
    "# Assume time_steps = 3 and model is already trained\n",
    "time_steps = 10\n",
    "\n",
    "# Get the last time_steps data points from the dataset to predict the next day\n",
    "last_data_points = scaled_features[-time_steps:]\n",
    "\n",
    "# Reshape the data to fit the model input shape (1, time_steps, number of features)\n",
    "last_data_points = last_data_points.reshape((1, time_steps, last_data_points.shape[1]))\n",
    "\n",
    "# Predict the future power output\n",
    "predicted_output = model.predict(last_data_points)\n",
    "\n",
    "# Inverse transform the prediction to get the actual value\n",
    "predicted_daily_yield = scaler.inverse_transform(predicted_output)\n",
    "\n",
    "print(f'Predicted Daily Yield for one day after the dataset ends: {predicted_daily_yield[0][0]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba786ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Day 1 predicted Daily Yield: 5680.96240234375\n",
      "Day 2 predicted Daily Yield: 590.1162109375\n",
      "Day 3 predicted Daily Yield: 1348.227783203125\n",
      "Day 4 predicted Daily Yield: 0.0\n",
      "Day 5 predicted Daily Yield: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize the array with the last data points from the scaled features\n",
    "input_sequence = scaled_features[-time_steps:].reshape((1, time_steps, scaled_features.shape[1]))\n",
    "\n",
    "# Predict the next 5 days\n",
    "predicted_daily_yields = []\n",
    "for i in range(5):  # for the next 5 days\n",
    "    # Predict the next day's yield using the model\n",
    "    daily_yield_prediction = model.predict(input_sequence)\n",
    "\n",
    "    # Store the predicted daily yield\n",
    "    predicted_daily_yields.append(scaler.inverse_transform(daily_yield_prediction)[0][0])\n",
    "\n",
    "    # Update the input sequence: remove the oldest day and add the predicted day\n",
    "    input_sequence = np.roll(input_sequence, -1, axis=1)\n",
    "    input_sequence[0, -1, :] = daily_yield_prediction\n",
    "\n",
    "# Display the predicted daily yields for the next 5 days\n",
    "for i, yield_prediction in enumerate(predicted_daily_yields, 1):\n",
    "    print(f\"Day {i} predicted Daily Yield: {yield_prediction}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d33042d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m853/853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step\n",
      "Mean Squared Error: 3343750.539753143\n",
      "Root Mean Squared Error: 1828.5925023780294\n",
      "Mean Absolute Error: 1202.0999917061379\n",
      "R-squared: 0.6369227844283137\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Make predictions on the test set\n",
    "predicted_test = model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions and actual values to their original scale\n",
    "predicted_test = scaler.inverse_transform(predicted_test)\n",
    "y_test_inverse = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate the MSE, RMSE, MAE, and R2 metrics\n",
    "mse = mean_squared_error(y_test_inverse, predicted_test)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test_inverse, predicted_test)\n",
    "r2 = r2_score(y_test_inverse, predicted_test)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'R-squared: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a4dd6c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Predicted Daily Yield for 3rd day: 0.0\n"
     ]
    }
   ],
   "source": [
    "time_steps = 3\n",
    "\n",
    "# Get the last time_steps data points from the dataset\n",
    "last_sequence = scaled_features[-time_steps:]\n",
    "\n",
    "for i in range(3):  # Predict for the next 3 days\n",
    "    # Reshape input for model\n",
    "    reshaped_sequence = last_sequence.reshape(1, time_steps, last_sequence.shape[-1])\n",
    "\n",
    "    # Predict next day\n",
    "    next_day_prediction = model.predict(reshaped_sequence)\n",
    "\n",
    "    # Replace nan values with 0\n",
    "    next_day_prediction = np.nan_to_num(next_day_prediction)\n",
    "\n",
    "    # Shift input sequence by 1 time step\n",
    "    last_sequence = np.roll(last_sequence, -1, axis=0)\n",
    "\n",
    "    # Replace last time step with predicted values\n",
    "    last_sequence[-1] = next_day_prediction[0]\n",
    "\n",
    "# The last element of last_sequence now contains predicted features for 3rd day\n",
    "predicted_daily_yield_third_day = scaler.inverse_transform(last_sequence[-1].reshape(1, -1))\n",
    "\n",
    "print(f'Predicted Daily Yield for 3rd day: {predicted_daily_yield_third_day[0][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ccfe1b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 2, the array at index 0 has size 6 and the array at index 1 has size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted Daily Yield for day \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mday_to_predict\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m after the dataset ends: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_daily_yield[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Update last_data_points with the new prediction for the next iteration\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     last_data_points \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(last_data_points, predicted_output\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, predicted_output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mappend\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:5499\u001b[0m, in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   5497\u001b[0m     values \u001b[38;5;241m=\u001b[39m ravel(values)\n\u001b[1;32m   5498\u001b[0m     axis \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 5499\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concatenate((arr, values), axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 2, the array at index 0 has size 6 and the array at index 1 has size 1"
     ]
    }
   ],
   "source": [
    "# Assuming time_steps, model, scaled_features, and scaler are already defined\n",
    "\n",
    "# Define the day to predict (e.g., day 3)\n",
    "day_to_predict = 3\n",
    "\n",
    "# Get the last time_steps data points from the dataset to predict the day\n",
    "last_data_points = scaled_features[-time_steps:]\n",
    "\n",
    "# Reshape the data to fit the model input shape (1, time_steps, number of features)\n",
    "last_data_points = last_data_points.reshape((1, time_steps, last_data_points.shape[1]))\n",
    "\n",
    "# Iterate to predict each day up to the desired day\n",
    "for day in range(1, day_to_predict + 1):\n",
    "    # Predict the future power output for the next day\n",
    "    predicted_output = model.predict(last_data_points)\n",
    "\n",
    "    # Inverse transform the prediction to get the actual value\n",
    "    predicted_daily_yield = scaler.inverse_transform(predicted_output)\n",
    "\n",
    "    if day == day_to_predict:\n",
    "        print(f'Predicted Daily Yield for day {day_to_predict} after the dataset ends: {predicted_daily_yield[0][0]}')\n",
    "    else:\n",
    "        # Update last_data_points with the new prediction for the next iteration\n",
    "        last_data_points = np.append(last_data_points, predicted_output.reshape((1, 1, predicted_output.shape[1])), axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fbc2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
